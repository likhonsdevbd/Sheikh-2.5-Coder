name: Automated Model Training

on:
  workflow_dispatch:
    inputs:
      gpu_type:
        description: 'GPU Type (a100, v100, t4)'
        required: true
        default: 'a100'
        type: choice
        options:
        - a100
        - v100
        - t4
      training_steps:
        description: 'Number of training steps'
        required: false
        default: '10000'
        type: string
      batch_size:
        description: 'Batch size'
        required: false
        default: '4'
        type: string
      learning_rate:
        description: 'Learning rate'
        required: false
        default: '2e-5'
        type: string
  
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday
  
  push:
    paths:
      - 'src/**'
      - 'scripts/**'
      - 'configs/**'
      - '.github/workflows/train.yml'

env:
  CUDA_VISIBLE_DEVICES: "0,1"

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      run-id: ${{ steps.setup.outputs.run-id }}
      timestamp: ${{ steps.setup.outputs.timestamp }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install datasets transformers accelerate evaluate torch torchvision torchaudio
          pip install huggingface_hub wandb git+https://github.com/google-research/google-research.git
          pip install datasets evaluate

      - name: Generate run ID and timestamp
        id: setup
        run: |
          echo "run-id=${{ github.run_id }}" >> $GITHUB_OUTPUT
          echo "timestamp=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT

  data-preparation:
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Cache processed datasets
        uses: actions/cache@v3
        with:
          path: |
            Sheikh-2.5-Coder/data/processed
            Sheikh-2.5-Coder/data/tokenized
          key: data-prep-${{ needs.setup.outputs.run-id }}-${{ hashFiles('configs/data_prep_config.yaml') }}
          restore-keys: |
            data-prep-${{ needs.setup.outputs.run-id }}-
            data-prep-

      - name: Run data preparation
        run: |
          python Sheikh-2.5-Coder/scripts/setup_training_env.py
          python Sheikh-2.5-Coder/scripts/prepare_data.py --config Sheikh-2.5-Coder/configs/data_prep_config.yaml

      - name: Upload processed data
        uses: actions/upload-artifact@v3
        with:
          name: processed-data-${{ needs.setup.outputs.run-id }}
          path: |
            Sheikh-2.5-Coder/data/processed/
            Sheikh-2.5-Coder/data/tokenized/

      - name: Data quality report
        run: |
          echo "## Data Preparation Report" >> $GITHUB_STEP_SUMMARY
          echo "Run ID: ${{ needs.setup.outputs.run-id }}" >> $GITHUB_STEP_SUMMARY
          echo "Timestamp: ${{ needs.setup.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "Dataset statistics:" >> $GITHUB_STEP_SUMMARY
          ls -la Sheikh-2.5-Coder/data/processed/ >> $GITHUB_STEP_SUMMARY
          wc -l Sheikh-2.5-Coder/data/processed/*.jsonl >> $GITHUB_STEP_SUMMARY

  training:
    runs-on: self-hosted
    needs: [setup, data-preparation]
    environment: 
      name: training-environment
      url: ${{ steps.deploy-model.outputs.url }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup GPU environment
        run: |
          nvidia-smi
          echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          python -c "import torch; print(f'GPU count: {torch.cuda.device_count()}')"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install training dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r Sheikh-2.5-Coder/requirements.txt
          pip install transformers datasets accelerate wandb evaluate torch
          pip install deepspeed bitsandbytes peft trl

      - name: Download processed data
        uses: actions/download-artifact@v3
        with:
          name: processed-data-${{ needs.setup.outputs.run-id }}
          path: Sheikh-2.5-Coder/data/

      - name: Cache model checkpoints
        uses: actions/cache@v3
        with:
          path: Sheikh-2.5-Coder/models/checkpoints/
          key: checkpoints-${{ github.event.inputs.gpu_type }}-${{ needs.setup.outputs.run-id }}
          restore-keys: |
            checkpoints-${{ github.event.inputs.gpu_type }}-
            checkpoints-

      - name: Setup W&B tracking
        run: |
          echo "${{ secrets.WANDB_API_KEY }}" | base64 -d > /tmp/wandb_key.txt
          export WANDB_API_KEY=$(cat /tmp/wandb_key.txt)
          export WANDB_PROJECT="sheikh-2.5-coder-training"
          export WANDB_ENTITY="${{ secrets.WANDB_ENTITY }}"
          echo "WANDB_API_KEY=${{ secrets.WANDB_API_KEY }}" >> $GITHUB_ENV
          echo "WANDB_PROJECT=sheikh-2.5-coder-training" >> $GITHUB_ENV
          echo "WANDB_ENTITY=${{ secrets.WANDB_ENTITY }}" >> $GITHUB_ENV

      - name: Run automated training
        id: training
        run: |
          cd Sheikh-2.5-Coder
          python scripts/auto_train.py \
            --model_name microsoft/phi-2 \
            --data_path data/processed \
            --output_path models/checkpoints \
            --gpu_type ${{ github.event.inputs.gpu_type }} \
            --training_steps ${{ github.event.inputs.training_steps }} \
            --batch_size ${{ github.event.inputs.batch_size }} \
            --learning_rate ${{ github.event.inputs.learning_rate }} \
            --run_id ${{ needs.setup.outputs.run-id }} \
            --timestamp ${{ needs.setup.outputs.timestamp }}

      - name: Upload model checkpoints
        uses: actions/upload-artifact@v3
        with:
          name: model-checkpoints-${{ needs.setup.outputs.run-id }}
          path: Sheikh-2.5-Coder/models/checkpoints/

      - name: Training metrics
        if: always()
        run: |
          echo "## Training Results" >> $GITHUB_STEP_SUMMARY
          echo "GPU Type: ${{ github.event.inputs.gpu_type }}" >> $GITHUB_STEP_SUMMARY
          echo "Training Steps: ${{ github.event.inputs.training_steps }}" >> $GITHUB_STEP_SUMMARY
          echo "Final Loss: $(tail -1 logs/training.log 2>/dev/null || echo 'N/A')" >> $GITHUB_STEP_SUMMARY
          
      - name: Checkpoint alert
        if: failure()
        run: |
          echo "Training failed - checkpoints saved for analysis" >> $GITHUB_STEP_SUMMARY

  evaluation:
    runs-on: ubuntu-latest
    needs: [setup, training]
    if: success()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install evaluation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install transformers datasets evaluate torch torchmetrics
          pip install numpy pandas matplotlib seaborn
          pip install datasets evaluate

      - name: Download model checkpoints
        uses: actions/download-artifact@v3
        with:
          name: model-checkpoints-${{ needs.setup.outputs.run-id }}
          path: Sheikh-2.5-Coder/models/

      - name: Run comprehensive evaluation
        run: |
          cd Sheikh-2.5-Coder
          python scripts/evaluate_model.py \
            --model_path models/checkpoints \
            --output_path evaluation/results \
            --run_id ${{ needs.setup.outputs.run-id }}

      - name: Upload evaluation results
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-results-${{ needs.setup.outputs.run-id }}
          path: Sheikh-2.5-Coder/evaluation/results/

      - name: Evaluation report
        run: |
          echo "## Model Evaluation Report" >> $GITHUB_STEP_SUMMARY
          echo "Run ID: ${{ needs.setup.outputs.run-id }}" >> $GITHUB_STEP_SUMMARY
          if [ -f "Sheikh-2.5-Coder/evaluation/results/eval_summary.md" ]; then
            cat Sheikh-2.5-Coder/evaluation/results/eval_summary.md >> $GITHUB_STEP_SUMMARY
          fi

      - name: Store benchmark results
        run: |
          # Store results for trend analysis
          echo "Storing benchmark results for historical tracking..."
          
  notify-success:
    runs-on: ubuntu-latest
    needs: [setup, training, evaluation]
    if: success()

    steps:
      - name: Success notification
        run: |
          echo "âœ… Training pipeline completed successfully!"
          echo "Run ID: ${{ needs.setup.outputs.run-id }}"
          echo "Model checkpoints and evaluation results are available as artifacts"